{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5084098-9de2-4d7b-8d00-7fd7ff67dc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import dask.array as da\n",
    "import glob\n",
    "from dask import array as da\n",
    "import os\n",
    "import numpy as np\n",
    "def read_im(path, return_pos=False):\n",
    "    dirname = os.path.dirname(path)\n",
    "    fov = os.path.basename(path).split('_')[-1].split('.')[0]\n",
    "    file_ = os.path.join(dirname, fov, 'data')\n",
    "    \n",
    "    xml_file = os.path.splitext(path)[0] + '.xml'\n",
    "    txt = open(xml_file, 'r').read()\n",
    "    tag = '<stage_position type=\"custom\">'\n",
    "    x, y = eval(txt.split(tag)[-1].split('</')[0])\n",
    "    if r'.fast.zarr' in txt:\n",
    "        image = da.from_zarr(path)\n",
    "        ncols = 5\n",
    "        image = image.reshape([-1,ncols,image.shape[-2],image.shape[-1]])\n",
    "        image = image.swapaxes(0,1)\n",
    "        if image.dtype == np.uint8:\n",
    "            image = image.astype(np.uint16) \n",
    "            image = image*image\n",
    "            image = da.array([image[1]+image[2],image[3],image[4],image[0]])\n",
    "    else:\n",
    "        image = da.from_zarr(file_)[1:]\n",
    "    \n",
    "        shape = image.shape\n",
    "        tag = '<z_offsets type=\"string\">'\n",
    "        zstack = txt.split(tag)[-1].split('</')[0]\n",
    "    \n",
    "        nchannels = int(zstack.split(':')[-1])\n",
    "        nzs = (shape[0] // nchannels) * nchannels\n",
    "        image = image[:nzs].reshape([shape[0] // nchannels, nchannels, shape[-2], shape[-1]])\n",
    "        image = image.swapaxes(0, 1)\n",
    "        if image.dtype == np.uint8:\n",
    "            image = image.astype(np.uint16) \n",
    "            image = image*image\n",
    "    \n",
    "    if return_pos:\n",
    "        return image, x, y\n",
    "    return image\n",
    "\n",
    "def _wiener_3d(self, image):\n",
    "    \"\"\"Monkey pathc to compute the 3D wiener deconvolution\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image: torch.Tensor\n",
    "        3D image tensor\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor of the 3D deblurred image\n",
    "\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    from sdeconv.core import SSettings\n",
    "    from sdeconv.deconv.wiener import pad_3d,laplacian_3d,unpad_3d\n",
    "    \n",
    "    image_pad, psf_pad, padding = pad_3d(image, self.psf / torch.sum(self.psf), self.pad)\n",
    "\n",
    "    fft_source = torch.fft.fftn(image_pad)\n",
    "    \n",
    "    container = SSettings.instance()\n",
    "    if not hasattr(container,'dic_psf'): container.dic_psf = {}\n",
    "    if container.dic_psf.get('den'+str(fft_source.shape),None) is None:        \n",
    "        psf_roll = torch.roll(psf_pad, int(-psf_pad.shape[0] / 2), dims=0)\n",
    "        psf_roll = torch.roll(psf_roll, int(-psf_pad.shape[1] / 2), dims=1)\n",
    "        psf_roll = torch.roll(psf_roll, int(-psf_pad.shape[2] / 2), dims=2)\n",
    "\n",
    "        fft_psf = torch.fft.fftn(psf_roll)\n",
    "        fft_laplacian = torch.fft.fftn(laplacian_3d(image_pad.shape))\n",
    "        den = fft_psf * torch.conj(fft_psf) + self.beta * fft_laplacian * torch.conj(fft_laplacian)\n",
    "        \n",
    "        \n",
    "        \n",
    "        container.dic_psf['den'+str(fft_source.shape)] = den\n",
    "        container.dic_psf['fft_psf'+str(fft_source.shape)] = fft_psf\n",
    "    else:\n",
    "        den = container.dic_psf['den'+str(fft_source.shape)].to(SSettings.instance().device)\n",
    "        fft_psf = container.dic_psf['fft_psf'+str(fft_source.shape)].to(SSettings.instance().device)\n",
    "    \n",
    "    out_image = torch.real(torch.fft.ifftn((fft_source * torch.conj(fft_psf)) / den))\n",
    "    if image_pad.shape != image.shape:\n",
    "        return unpad_3d(out_image, padding)\n",
    "    return out_image\n",
    "def apply_deconv(imsm,psf=None,plt_val=False,parameters = {'method':'wiener','beta':0.001,'niter':50},gpu=False,force=False,pad=None):\n",
    "    r\"\"\"Applies deconvolution to image <imsm> using sdeconv: https://github.com/sylvainprigent/sdeconv/\n",
    "    Currently assumes 60x objective with ~1.4 NA using SPSFGibsonLanni. Should be modified to find \n",
    "    \n",
    "    Recomendations: the default wiener method with a low beta is the best for very fast local fitting. Albeit larger scale artifacts.\n",
    "    For images: recommend the lucy method with ~30 iterations.\n",
    "    \n",
    "    This wraps around pytoch.\n",
    "    \n",
    "    To install:\n",
    "    pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117\n",
    "    pip install sdeconv\n",
    "    Optional: decided to modify the __init__ file of the SSettingsContainer in \n",
    "    C:\\Users\\BintuLabUser\\anaconda3\\envs\\cellpose\\Lib\\site-packages\\sdeconv\\core\\_settings.py\n",
    "    \n",
    "    import os\n",
    "    gpu = True\n",
    "    if os.path.exists(\"use_gpu.txt\"):\n",
    "        gpu = eval(open(\"use_gpu.txt\").read())\n",
    "    self.device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and gpu) else \"cpu\")\n",
    "    to toggle the GPU on or off. By default it just uses the GPU if GPU detected by pytorch\"\"\"\n",
    "    \n",
    "    #import sdeconv,os\n",
    "    #fl = os.path.dirname(sdeconv.__file__)+os.sep+'core'+os.sep+'use_gpu.txt'\n",
    "    #fid = open(fl,'w')\n",
    "    #fid.write('True')\n",
    "    #fid.close()\n",
    "    import torch\n",
    "    from sdeconv.core import SSettings\n",
    "    obj = SSettings.instance()\n",
    "    obj.device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and gpu) else \"cpu\")\n",
    "    if force:\n",
    "        if hasattr(obj,'dic_psf'): del obj.dic_psf\n",
    "    # map to tensor\n",
    "    \n",
    "    imsm_ = torch.from_numpy(np.array(imsm,dtype=np.float32))\n",
    "    if psf is None:\n",
    "        from sdeconv.psfs import SPSFGibsonLanni\n",
    "        #psf_generator = SPSFGaussian((1,1.5, 1.5), imsm_.shape)\n",
    "        psf_generator = SPSFGibsonLanni(M=60,shape=imsm_.shape)\n",
    "        psf = psf_generator().to(obj.device)\n",
    "    else:\n",
    "        psff = np.zeros(imsm_.shape,dtype=np.float32)\n",
    "                \n",
    "        slices = [(slice((s_psff-s_psf_full_)//2,(s_psff+s_psf_full_)//2),slice(None)) if s_psff>s_psf_full_ else\n",
    "         (slice(None),slice((s_psf_full_-s_psff)//2,(s_psf_full_+s_psff)//2))\n",
    "          \n",
    "          for s_psff,s_psf_full_ in zip(psff.shape,psf.shape)]\n",
    "        sl_psff,sl_psf_full_ = list(zip(*slices))\n",
    "        psff[sl_psff]=psf[sl_psf_full_]\n",
    "        psf = torch.from_numpy(np.array(psff,dtype=np.float32)).to(obj.device)\n",
    "        \n",
    "    method = parameters.get('method','wiener')\n",
    "    if pad is None:\n",
    "        pad = int(np.min(list(np.array(imsm.shape)-1)+[50]))\n",
    "    if method=='wiener':\n",
    "        from sdeconv.deconv import SWiener\n",
    "        beta = parameters.get('beta',0.001)\n",
    "        filter_ = SWiener(psf, beta=beta, pad=pad)\n",
    "        #monkey patch _wiener_3d to allow recycling the fft of the psf components\n",
    "        filter_._wiener_3d = _wiener_3d.__get__(filter_, SWiener)\n",
    "    elif method=='lucy':\n",
    "        from sdeconv.deconv import SRichardsonLucy\n",
    "        niter = parameters.get('niter',50)\n",
    "        filter_ = SRichardsonLucy(psf, niter=niter, pad=pad)\n",
    "    elif method=='spitfire':\n",
    "        from sdeconv.deconv import Spitfire\n",
    "        filter_ = Spitfire(psf, weight=0.6, reg=0.995, gradient_step=0.01, precision=1e-6, pad=pad)\n",
    "    out_image = filter_(imsm_)\n",
    "    out_image = out_image.cpu().detach().numpy().astype(np.float32)\n",
    "    if plt_val:\n",
    "        import napari\n",
    "        viewer = napari.view_image(out_image)\n",
    "        viewer.add_image(imsm)\n",
    "    return out_image\n",
    "def full_deconv(im_,s_=300,pad=100,psf=None,parameters={'method': 'wiener', 'beta': 0.001, 'niter': 50},gpu=True,force=True):\n",
    "    im0=np.zeros_like(im_)\n",
    "    sx,sy = im_.shape[1:]\n",
    "    ixys = []\n",
    "    for ix in np.arange(0,sx,s_):\n",
    "        for iy in np.arange(0,sy,s_):\n",
    "            ixys.append([ix,iy])\n",
    "    \n",
    "    for ix,iy in ixys:#ixys:#tqdm(ixys):\n",
    "        imsm = im_[:,ix:ix+pad+s_,iy:iy+pad+s_]\n",
    "        if type(psf) is dict:\n",
    "            keys = list(psf.keys())\n",
    "            ikey = np.argmin(np.sum(np.abs(np.array(keys)-[0,ix,iy]),axis=-1))\n",
    "            psf_ = psf[keys[ikey]]\n",
    "            force=True\n",
    "        else:\n",
    "            psf_ = psf\n",
    "        imt = apply_deconv(imsm,psf=psf_,parameters=parameters,gpu=gpu,plt_val=False,force=force)\n",
    "        start_x = ix+pad//2 if ix>0 else 0\n",
    "        end_x = ix+pad//2+s_\n",
    "        start_y = iy+pad//2 if iy>0 else 0\n",
    "        end_y = iy+pad//2+s_\n",
    "        #print(start_x,end_x,start_y,end_y)\n",
    "        im0[:,start_x:end_x,start_y:end_y] = imt[:,(start_x-ix):(end_x-ix),(start_y-iy):(end_y-iy)]\n",
    "    return im0\n",
    "from tqdm import tqdm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07371cb1-edd3-4141-aaf6-48271f2f7f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_segms  = np.sort(glob.glob(r'Z:\\MERFISHp\\12_16_2025_BigSlideTest\\Segmentation2d\\Conv_zscan6_*.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53003c50-aa88-4dd6-9bd8-4a415ebba015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'segm' at 0x15a93cb3df0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fl_segm = fl_segms[590]\n",
    "fov,htag,_ = os.path.basename(fl_segm).split('--')\n",
    "fl_raw = rf'Z:\\MERFISHp\\12_16_2025_BigSlideTest\\{htag}\\{fov}.zarr'\n",
    "imdapi = read_im(fl_raw)[-1]\n",
    "segm = np.load(fl_segm)['segm']\n",
    "shape = np.load(fl_segm)['shape']\n",
    "resc = np.round(shape/segm.shape).astype(int)\n",
    "imdapi = imdapi[::resc[0],::resc[1],::resc[2]]\n",
    "#segm2d = np.load(fl_segm.replace('Segmentation','Segmentation2d'))['segm']\n",
    "import napari\n",
    "V = napari.Viewer()\n",
    "V.add_image(imdapi)\n",
    "V.add_labels(segm)\n",
    "#V.add_labels(segm2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01c2d137-bd6a-4446-b66f-871231bf8750",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e68e9c36-ea36-4680-9330-0a1033fde353",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fls = np.sort(glob.glob(r'Z:\\MERFISHp\\12_16_2025_BigSlideTest\\H1_MER_set*\\*.zarr'))\n",
    "all_fls = list(all_fls[560:])+list(all_fls[:560])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ca28f97-35c7-41ba-8cf8-74dddce7b304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6302"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_fls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f751e3d-edc3-443f-91fd-07f57dc3d565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellpose import models, io\n",
    "# Load model\n",
    "model = models.CellposeModel(gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796de7ef-735d-4b04-ae9d-e4c2c43a7e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████████████████████████████████████████████████████████▉                | 4974/6302 [00:23<00:01, 1043.41it/s]\n",
      "  0%|                                                                                           | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|████████▌                                                                          | 4/39 [00:00<00:00, 39.02it/s]\u001b[A\n",
      " 23%|███████████████████▏                                                               | 9/39 [00:00<00:00, 42.91it/s]\u001b[A\n",
      " 36%|█████████████████████████████▍                                                    | 14/39 [00:00<00:00, 43.26it/s]\u001b[A\n",
      " 49%|███████████████████████████████████████▉                                          | 19/39 [00:00<00:00, 42.15it/s]\u001b[A\n",
      " 62%|██████████████████████████████████████████████████▍                               | 24/39 [00:00<00:00, 42.56it/s]\u001b[A\n",
      " 74%|████████████████████████████████████████████████████████████▉                     | 29/39 [00:00<00:00, 42.55it/s]\u001b[A\n",
      " 87%|███████████████████████████████████████████████████████████████████████▍          | 34/39 [00:00<00:00, 43.40it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 43.08it/s]\u001b[A\n",
      " 80%|██████████████████████████████████████████████████████████████                | 5013/6302 [00:38<02:30,  8.58it/s]\n",
      "  0%|                                                                                           | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|████████▌                                                                          | 4/39 [00:00<00:00, 38.19it/s]\u001b[A\n",
      " 23%|███████████████████▏                                                               | 9/39 [00:00<00:00, 41.53it/s]\u001b[A\n",
      " 36%|█████████████████████████████▍                                                    | 14/39 [00:00<00:00, 42.56it/s]\u001b[A\n",
      " 49%|███████████████████████████████████████▉                                          | 19/39 [00:00<00:00, 42.87it/s]\u001b[A\n",
      " 62%|██████████████████████████████████████████████████▍                               | 24/39 [00:00<00:00, 43.29it/s]\u001b[A\n",
      " 74%|████████████████████████████████████████████████████████████▉                     | 29/39 [00:00<00:00, 43.22it/s]\u001b[A\n",
      " 87%|███████████████████████████████████████████████████████████████████████▍          | 34/39 [00:00<00:00, 43.05it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 42.59it/s]\u001b[A\n",
      " 80%|██████████████████████████████████████████████████████████████                | 5014/6302 [01:11<06:00,  3.58it/s]"
     ]
    }
   ],
   "source": [
    "for fl in tqdm(all_fls):\n",
    "    fov = os.path.basename(fl).replace('.zarr','')\n",
    "    htag = os.path.basename(os.path.dirname(fl))\n",
    "    fl_segm = rf'Z:\\MERFISHp\\12_16_2025_BigSlideTest\\Segmentation2d\\{fov}--{htag}--segm.npz'\n",
    "    if not os.path.exists(fl_segm):\n",
    "        immed = np.load(r'Z:\\MERFISHp\\12_16_2025_BigSlideTest\\V2_med3.npy')\n",
    "        immed=immed/np.median(immed)\n",
    "        immed = cv2.blur(immed,(20,20))\n",
    "        im_dapi = np.array(read_im(fl)[-1],dtype=np.float32)/immed\n",
    "        imdo = full_deconv(im_dapi,s_=400,pad=100,psf=np.load(r'Z:\\MERFISHp\\12_16_2025_BigSlideTest\\psf_single.npy'),\n",
    "                    parameters={'method': 'wiener', 'beta': 0.005, 'niter': 50},gpu=True,force=False)\n",
    "        \n",
    "        img = np.clip(imdo[:,::3,::3]/50000,0,1)\n",
    "        res = model.eval(img,\n",
    "                                batch_size=8,\n",
    "                                resample=False,\n",
    "                                channel_axis=None,\n",
    "                                z_axis=0,\n",
    "                                normalize=False,\n",
    "                                invert=False,\n",
    "                                rescale=None,\n",
    "                                diameter=None,\n",
    "                                flow_threshold=-10,\n",
    "                                cellprob_threshold=-10,\n",
    "                                do_3D=False,\n",
    "                                anisotropy=None,\n",
    "                                flow3D_smooth=5,\n",
    "                                stitch_threshold=0.5,\n",
    "                                min_size=400,\n",
    "                                max_size_fraction=0.4,\n",
    "                                niter=None,\n",
    "                                augment=False,\n",
    "                                tile_overlap=0.1,\n",
    "                                bsize=256,\n",
    "                                compute_masks=True,\n",
    "                                progress=True,\n",
    "                            )\n",
    "        \n",
    "        \n",
    "        mask = res[0].copy()\n",
    "        ucells,volms  = np.unique(mask,return_counts=True)\n",
    "        mask[np.isin(mask,ucells[volms<5000])]=0\n",
    "        np.savez_compressed(fl_segm,segm = mask,shape=im_dapi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5369263f-c2d5-431c-a6d2-a6bcaba352e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bf42a1-4ce2-485a-b642-b9d820e75d95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "441ee3fc-44a6-4225-87d8-1fac0e28d986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z:\\MERFISHp\\12_16_2025_BigSlideTest\\Segmentation\\Conv_zscan4__210--H1_MER_set4--segm.npz\n"
     ]
    }
   ],
   "source": [
    "print(fl_segm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a294a92f-17fd-4651-9647-42cc51542812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(4914.768840299134)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(8.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "84db69ee-c928-4ba9-bda3-4e7f6bb15402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(46399.5)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(volms[volms>2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a42032-df39-4d23-91c8-deeea26d5904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2bef2076-6f5d-4311-bc20-eff9f58a1324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'Labels' at 0x2169b5cb700>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ec210b-1d8d-4a78-8baa-90ea21c672fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff038876-b302-4037-aa54-7cd0e0e9951f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'Image' at 0x21630950c70>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import napari\n",
    "V = napari.Viewer()\n",
    "V.add_image(imdo[:,::3,::3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b470e4fc-34c9-4435-af3f-aee6b8ecf3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:04<00:00, 10.25it/s]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2b80c9a-8fe5-4513-8165-2e0c8e6c13c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miket\\AppData\\Local\\Temp\\ipykernel_23192\\4228981805.py:1: FutureWarning: `napari.view_image` is deprecated and will be removed in napari 0.7.0.\n",
      "Use `viewer = napari.Viewer(); viewer.add_image(...)` instead.\n",
      "  napari.view_image(imd[:,::3,::3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Viewer(camera=Camera(center=(0.0, np.float64(466.5), np.float64(466.5)), zoom=np.float64(0.6102783725910064), angles=(0.0, 0.0, 90.0), perspective=0.0, mouse_pan=True, mouse_zoom=True, orientation=(<DepthAxisOrientation.TOWARDS: 'towards'>, <VerticalAxisOrientation.DOWN: 'down'>, <HorizontalAxisOrientation.RIGHT: 'right'>)), cursor=Cursor(position=(np.float64(19.0), 1.0, 0.0), viewbox=None, scaled=True, style=<CursorStyle.STANDARD: 'standard'>, size=1.0), dims=Dims(ndim=3, ndisplay=2, order=(0, 1, 2), axis_labels=('0', '1', '2'), rollable=(True, True, True), range=(RangeTuple(start=np.float64(0.0), stop=np.float64(39.0), step=np.float64(1.0)), RangeTuple(start=np.float64(0.0), stop=np.float64(933.0), step=np.float64(1.0)), RangeTuple(start=np.float64(0.0), stop=np.float64(933.0), step=np.float64(1.0))), margin_left=(0.0, 0.0, 0.0), margin_right=(0.0, 0.0, 0.0), point=(np.float64(19.0), np.float64(466.0), np.float64(466.0)), last_used=0), grid=GridCanvas(stride=1, shape=(-1, -1), enabled=False, spacing=0.0), layers=[<Image layer 'Image' at 0x215c6e409d0>], help='use <2> for transform', status='Ready', tooltip=Tooltip(visible=False, text=''), theme='dark', title='napari', mouse_over_canvas=False, mouse_move_callbacks=[], mouse_drag_callbacks=[<function drag_to_zoom at 0x000002157DB0C790>], mouse_double_click_callbacks=[<function double_click_to_zoom at 0x000002157DB0C700>], mouse_wheel_callbacks=[<function dims_scroll at 0x000002157DAE7BE0>], _persisted_mouse_event={}, _mouse_drag_gen={}, _mouse_wheel_gen={}, _keymap={})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf341b0-98d7-4676-bca8-b671a69f91e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
